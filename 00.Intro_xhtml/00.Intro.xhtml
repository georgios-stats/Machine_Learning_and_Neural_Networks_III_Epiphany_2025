<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta name="generator" content="LyX 2.4.2.1" />
<title>LyX Document</title>
<style>
/* Layout-provided Styles */
del.strikeout {
  text-decoration: line-through;
}
div.standard {
text-align: left;

}
h2.section_ {
font-weight: normal;
font-style: normal;
font-variant: small-caps;
font-size: medium;
margin-top: 1.3ex;
margin-bottom: 0.7ex;
text-align: center;

}
div.plain_layout {
text-align: left;

}
ul.itemize {
margin-top: 0.7ex;
margin-bottom: 0.7ex;
margin-left: 3ex;
text-align: left;

}
ol.enumi   { list-style-type: decimal; }
ol.enumii  { list-style-type: lower-latin; }
ol.enumiii { list-style-type: lower-roman; }
ol.enumiv  { list-style-type: upper-latin; }
div.Frameless { margin: 1em; }
span.flex_url {
font-family: monospace;
}


</style>
</head>
<body dir="auto">


<div class='standard' id='magicparlabel-37'><br /></div>
<h2 class='section_' id='magicparlabel-38'>Reading list</h2>
<div class='standard' id='magicparlabel-39'><div class='Frameless' style='width: 45%; '>
</div><div class='Frameless' style='width: 45%; '>
</div></div>

<div class='standard' id='magicparlabel-48'>These lecture Handouts have been derived based on the reading list below.</div>

<div class='standard' id='magicparlabel-49'><u>Main texts:</u></div>
<ul class='lyxitem lyxitemi'>
<li class="itemize_item" id='magicparlabel-50'>Bishop, C. M. (2006). Pattern recognition and machine learning. New York: Springer.
<ul class='lyxitem lyxitemii'>
<li class="itemize_item" id='magicparlabel-51'>It is a classical textbook in machine learning (ML) methods. It discusses all the concepts introduced in the course (not necessarily in the same depth). It is one of the main textbooks in the module. The level on difficulty is easy.</li>
<li class="itemize_item" id='magicparlabel-52'>Students who wish to have a textbook covering traditional concepts in machine learning are suggested to get a copy of this textbook. It is available online from the Microsoft&#8217;s website <span class='flex_url'>https://www.microsoft.com/en-us/research/publication/pattern-recognition-machine-learning/</span></li>
</ul>
</li><li class="itemize_item" id='magicparlabel-57'>Shalev-Shwartz, S., &amp; Ben-David, S. (2014). Understanding machine learning: From theory to algorithms. Cambridge university press. 
<ul class='lyxitem lyxitemii'>
<li class="itemize_item" id='magicparlabel-58'>It has several elements of theory about machine learning algorithms. It is one of the main textbooks in the module. The level on difficulty is advanced as it requires moderate knowledge of maths.</li>
</ul>
</li><li class="itemize_item" id='magicparlabel-59'>Bishop, C. M. (1995). Neural networks for pattern recognition. Oxford university press.
<ul class='lyxitem lyxitemii'>
<li class="itemize_item" id='magicparlabel-60'>It is a classical textbook about `traditional&#8217; artificial neural networks (ANN). It is very comprehensive (compared to others) and it goes deep enough for the module although it may be a bit outdated. It is one of the main textbooks in the module for ANN. The level on difficulty is moderate.</li>
</ul>
</li></ul>
<div class='standard' id='magicparlabel-61'><u>Supplementary textbooks:</u></div>
<ul class='lyxitem lyxitemi'>
<li class="itemize_item" id='magicparlabel-62'>Vapnik, V. (1999). The nature of statistical learning theory. Springer science &amp; business media.
<ul class='lyxitem lyxitemii'>
<li class="itemize_item" id='magicparlabel-63'>Important textbook in the statistical machine learning theory. To have have an in deep understanding about statistical learning, one has to read it together with the textbook of Shalev-Shwartz, S., &amp; Ben-David, S. (2014)</li>
</ul>
</li><li class="itemize_item" id='magicparlabel-64'>Devroye, L., Györfi, L., &amp; Lugosi, G. (2013). A probabilistic theory of pattern recognition (Vol. 31). Springer Science &amp; Business Media.
<ul class='lyxitem lyxitemii'>
<li class="itemize_item" id='magicparlabel-65'>Important textbook in the theoretical aspects about machine learning algorithms. The level on difficulty is advanced as it requires moderate knowledge of probability.</li>
</ul>
</li><li class="itemize_item" id='magicparlabel-66'>Theodoridis, S. (2015). Machine learning: a Bayesian and optimization perspective. Academic press.
<ul class='lyxitem lyxitemii'>
<li class="itemize_item" id='magicparlabel-67'>A textbook in general machine learning methods. It includes a large collection of different machine learning methods. It does not go too deep into the theoretical details of the method. </li>
</ul>
</li><li class="itemize_item" id='magicparlabel-68'>Murphy, K. P. (2012). Machine learning: a probabilistic perspective. MIT press.
<ul class='lyxitem lyxitemii'>
<li class="itemize_item" id='magicparlabel-69'>A popular textbook in general machine learning methods. It discusses all the concepts introduced in the module. It focuses more on the probabilistic/Bayesian framework but not with great detail. It can be used as a comparison textbook for brief reading about ML methods just to see another perspective than that in (Bishop, C. M., 2006). The level on difficulty is easy.</li>
</ul>
</li><li class="itemize_item" id='magicparlabel-70'>Murphy, K. P. (2022). Probabilistic machine learning: an introduction. MIT press.
<ul class='lyxitem lyxitemii'>
<li class="itemize_item" id='magicparlabel-71'>A textbook in general machine learning methods. It covers a smaller number of ML concepts than (Murphy, K. P., 2012) but it contains more fancy/popular topics such as deep learning ideas. It is suggested to be used in the same manner as (Murphy, K. P., 2012). The level on difficulty is easy.</li>
</ul>
</li><li class="itemize_item" id='magicparlabel-77'>Bishop, C. M., &amp; Bishop, H. (2024). Deep learning: foundations and concepts. New York: Springer.
<ul class='lyxitem lyxitemii'>
<li class="itemize_item" id='magicparlabel-78'>A textbook in machine learning methods focusing on Neural Networks philosophy and deep learning. Essentially, this is an update of the earlier book &#8220;Bishop, C. M. (1995). Neural networks for pattern recognition. Oxford university press.&#8221; where: the concepts about Neural networks, stochastic gradient descent have been extended; new deep learning concepts have been added; and the kernel methods are left out. </li>
</ul>
</li><li class="itemize_item" id='magicparlabel-79'>Ripley, B. D. (2007). Pattern recognition and neural networks. Cambridge university press.
<ul class='lyxitem lyxitemii'>
<li class="itemize_item" id='magicparlabel-80'>A classical textbook in artificial neural networks (ANN) that also covers other machine learning concepts. It contains interesting theory about ANN. </li>
<li class="itemize_item" id='magicparlabel-81'>It is suggested to be used as a supplementary reading for neural networks as it contains a few interesting theoretical results. The level on difficulty is moderate.</li>
</ul>
</li><li class="itemize_item" id='magicparlabel-82'>Williams, C. K., &amp; Rasmussen, C. E. (2006). Gaussian processes for machine learning (Vol. 2, No. 3, p. 4). Cambridge, MA: MIT press.
<ul class='lyxitem lyxitemii'>
<li class="itemize_item" id='magicparlabel-83'>A classic book in Gaussian process regression (GPR) that covers the material we will discuss in the course about GPR. It can be used as a companion textbook with that of (Bishop, C. M., 2006). The level on difficulty is easy.</li>
</ul>
</li></ul>
<div class='standard' id='magicparlabel-84'><u>Preparatory textbooks:</u></div>
<ul class='lyxitem lyxitemi'>
<li class="itemize_item" id='magicparlabel-85'>Strang, G. (2019). Linear algebra and learning from data. Wellesley-Cambridge Press.
<ul class='lyxitem lyxitemii'>
<li class="itemize_item" id='magicparlabel-86'>Material regarding linear algebra concepts. </li>
</ul>
</li><li class="itemize_item" id='magicparlabel-87'>Boyd, S. P., &amp; Vandenberghe, L. (2004). Convex optimization. Cambridge university press.
<ul class='lyxitem lyxitemii'>
<li class="itemize_item" id='magicparlabel-88'>Material regarding Convex optimization, quadratic optimization, Lagrange duality.</li>
</ul>
</li></ul>
<div class='standard' id='magicparlabel-89'>
<br />
</div>

<div class='standard' id='magicparlabel-90'><br /></div>
<h2 class='section_' id='magicparlabel-91'>Contents</h2>
<ol class='lyxenum enumi'>
<li class="enumerate_item" id='magicparlabel-92'><a id="enu_Handout_0__Machine" /> Lecture notes <a href="#enu_Handout_0__Machine">1.</a>: Machine learning –A recap on: definitions, notation, and formalism </li>
<li class="enumerate_item" id='magicparlabel-93'><a id="enu_Handout__Elements_of" /> Lecture notes <a href="#enu_Handout__Elements_of">2.</a>: Elements of convex learning problems </li>
<li class="enumerate_item" id='magicparlabel-94'><a id="enu_Handout___Learnability_" /> Lecture notes <a href="#enu_Handout___Learnability_">3.</a>: Learnability, and stability</li>
<li class="enumerate_item" id='magicparlabel-95'><a id="enu_Handout___Gradient" /> Lecture notes <a href="#enu_Handout___Gradient">4.</a>: Gradient descent </li>
<li class="enumerate_item" id='magicparlabel-96'><a id="enu_Handout___Stochastic" /> Lecture notes <a href="#enu_Handout___Stochastic">5.</a>: Stochastic gradient descent </li>
<li class="enumerate_item" id='magicparlabel-97'><a id="enu_Handout___Stochastic_1" /> Lecture notes <a href="#enu_Handout___Stochastic_1">6.</a>: Variations of stochastic gradient descent </li>
<li class="enumerate_item" id='magicparlabel-98'><a id="enu_Handout___Bayesian" /> Lecture notes <a href="#enu_Handout___Bayesian">7.</a>: Bayesian Learning via Stochastic gradient and Stochastic gradient Langevin dynamics</li>
<li class="enumerate_item" id='magicparlabel-99'><a id="enu_Handout___Support" /> Lecture notes <a href="#enu_Handout___Support">8.</a>: Support Vector Machines</li>
<li class="enumerate_item" id='magicparlabel-100'><a id="enu_Handout___Kernel" /> Lecture notes <a href="#enu_Handout___Kernel">9.</a>: Kernel methods</li>
<li class="enumerate_item" id='magicparlabel-101'><a id="enu_Handout___Multi_class" /> Lecture notes <a href="#enu_Handout___Multi_class">10.</a>: Multi-class classification</li>
<li class="enumerate_item" id='magicparlabel-102'><a id="enu_Handout___Artificial" /> Lecture notes <a href="#enu_Handout___Artificial">11.</a>: Artificial neural networks</li>
<li class="enumerate_item" id='magicparlabel-103'><a id="enu_Handout___Gaussian" /> Lecture notes <a href="#enu_Handout___Gaussian">12.</a>: Gaussian process regression</li>
</ol>
</body>
</html>
